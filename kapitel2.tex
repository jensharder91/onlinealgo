\chapter{Paging}

\section{Deterministische Algorithmen}

\subsection{Markierungsalgorithmen}
$\sigma = (\overbrace{1, 2, 4, 2, 1}^{Phase 1},\overbrace{3, 5, 2, 3, 5}^{Phase 2},\overbrace{1, 2, 3}^{Phase 3},\overbrace{4}^{Phase 4})$



\textbf{Theorem 2.1.} LRU und FWF sind Markierungsalgorithmen

\textit{Beweis:} Widerspruchsbeweis: In der Phase müsste auf $k + 1$ verschiedene Seiten zugegriffen werden, damit eine markierte Seite verdrängt wird. (Widerspruch!)



\textbf{Theorem 2.2.} Jeder Markierungsalgorithmus ist strikt k-kompetitiv

\textit{Beweis:}
\begin{enumerate}
\item Fall: es gibt nur eine Phase: keine Seite wird jemals verdrängt: Markierungsalgorithmus ist optimal
\item Fall: es gibt mind. 2 Phasen: Kosten $\le l \cdot k$ (Anzahl Phasen mal Anzahl versch. Seiten / Phase).
\end{enumerate}
Annahme: opt. Offline Algo. macht mind. $(k + l - 2)$ Seitenfehler ($k$ in der ersten Phase, in jeder weiteren Phase (außer in der letzten) mind. einen Seitenfehler).

Teilsequenzen $(k=3)$:

$\sigma = (\overbrace{1, 2, 4, 2, 1}^{Phase 1},\overbrace{3, 5, 2, 3, 5}^{Phase 2},\overbrace{1, 2, 3}^{Phase 3},\overbrace{4}^{Phase 4})$\\
$\sigma = (1, 2, 4, 2, 1, \overbracket{3}^{x}, \underbracket{5, 2, 3, 5, 1}_{T1}, \underbracket{2, 3, 4}_{T2})$

pro Teilsequenz mind. 1 Seitenfehler, da z.B. in T1 $k$ Seiten sind, die sich von $x$ unterscheiden $\to$ 1 Seitenfehler.
Also: $\omega_{A}(\sigma) \le l \cdot k \le (k + l - 2) \cdot k \le \textrm{OPT}(\sigma) \cdot k$



\textbf{Korollar 2.3.} LRU und FWF sind strikt k-kompetitiv



\textbf{Theorem 2.4.} LFU und LIFO sind nicht kompetitiv
\textit{Beweis:} Gebe Gegenbeispiel an:

$\sigma = \left(1^l, 1^l, ..., (k-1)^l, (k, k+1)^l\right)$\\
$\Rightarrow k - 1 + 2(l - 1)$ Seitenfehler

\begin{align*}
\omega_{\textrm{LFU}}(\sigma) = \omega_{\textrm{LIFO}}(\sigma) &> r \cdot \textrm{OPT}(\sigma + \tau)\\
\Leftrightarrow k - 1 + 2 (l - 1) &> r \cdot (k + 1) + \tau \textrm{ für hinreichend große } l
\end{align*}



\textbf{Theorem 2.5.} Es gibt für kein $r < k$ einen deterministischen $r$-kompetitiven online Algorithmus für das Paging-Problem

\textit{Beweis:} Konstruiere Eingabe für bel. online Algo A: $\sigma_{1}$, $\sigma_{2}$, ..., $\sigma_{k}$: k verschiedene Seitem. Also hat sowohl A als auch opt. offline Algo k Seitenfehler.\\
Für $\sigma_{k + 1}$, ..., $\sigma_{k + l}$ gilt: Es kommt immer die Seite, die A vorher aus dem Cach geschmissen hat. Also macht A hier k + l Seitenfehler; LFD hat nur $\omega_{LFD}$($\sigma$) $\le$ k + 1 + $\tfrac{l}{k}$ Seitenfehler. \\
Da LFD mind. so viele Fehler macht wie OPT gilt: $\omega_{A}$($\sigma$) = k + l $>$ r $\cdot$ ( k + 1 + $\tfrac{l}{k}$) + $\tau$ $\ge$ r $\cdot$ $\omega_{LFO}$($\sigma$) + $\tau$ \\
 $\Rightarrow$  $\omega_{A}$($\sigma$) $>$ r $\cdot$ OPT($\sigma$) $\cot$ r


\subsection{Untere Schranken}


\subsection{Optimaler Offline-Algorithmus}

\textbf{Theorem 2.6.} LFD ist ein optimaler offline Algorithmus für das Paging-Problem

\textit{Beweis mit Lemma 2.7}:

\textbf{Lemma 2.7.} Sei $A$ ein bel. offline Algo, der sich auf Eingabe $\sigma$ anders verhält als LFD uns sei $\sigma_{t}$ der erste Seitenzugriff, bei dem sich A und LFD unterscheiden. Dann ex. Algo B mit folgenden Eingenschaften:
\begin{enumerate}
\item B verhält sich auf $\sigma_{1}, ..., \sigma_{t - 1}$ genau wie A
\item Bei $\sigma_{t}$ verdrängt B die Seite, bei der der mächste Zugriff am weitesten weg ist
\item B verursacht auf $\sigma$ höchstens so viele Fehler wie Algo A
\end{enumerate}

\textit{Beweis Theorem 2.6:}\\
Man verwendet (höchstens n - mal) Lemma 2.7 so oft hintereinander an, bis sich Algo B genauso verhält wie LFD. Da dieser dann (laut Lemma) höchstens so viele Fehler macht wie OPT ist LFD optimal.\\
$\omega_{LFD}(\sigma) = \omega_{A_{n}}(\sigma) \le \omega_{A_{n-1}}(\sigma) \le ... \le \omega_{A_{1}}(\sigma) \le \omega_{OPT}(\sigma)$ \\

\textit{Beweis Lemma 2.7:}\\
Wir konstruieren nun Algo B: \\
Auf der Sequent $\sigma_{1}, ..., \sigma_{t-1}$ verhalten sich die Algorithmen A und B gleich. bei $\sigma_{t}$ machen beide einen Seitenfehler, verdrängen aber unterschieldiche Seiten aus dem Cach.

TODO: !!!Beweis Lemma 2.7!!!

\subsection{Zusammenfassung der Ergebnisse}

\begin{tabular}{| l | l | l |}
\hline
LRU  & least-recently-used      & strikt $k$-kompetitiv da Markierungsalgorithmus \\ \hline
FWF  & flush-when-full          & strikt $k$-kompetitiv da Markierungsalgorithmus \\ \hline
FIFO & first-in-first-out       & kein Markierungsalgorithmus, dennoch $k$-kompetitiv \\ \hline
LFU  & least-frequently-used    & nicht kompetitiv\\ \hline
LIFO & last-in-first-out        & nicht kompetitiv\\ \hline
LFD  & longest-forward-distance & optimaler Offline-Algorithmus \\ \hline
\end{tabular}



\section{Randomisierte Algorithmen}


\textbf{Definition 2.8} Ein randomisierter Online-Algorithmus $A$ für ein Minimierungsproblem $\Pi$ erreicht einen kompetitiven Faktor von $r \ge 1$, wenn es eine Konstante $r \in \mathbb{R}$ gibt, sodass
$$E[w_A(\sigma)] \leq r \cdot \textrm{OPT}(\sigma) + \tau$$
für alle Instanzen $\sigma \in I_\Pi$ gilt. Gilt diese Ungleichung sogar für $\tau = 0$, so ist $A$ strikt $r$-kompetitiv.

Der Unterschied zu Definition 1.1 besteht lediglich darin, dass wir hier den Erwartungswert der Kosten nutzen, da diese vom Zufall abhängen.

\subsection{Potentialfunktionen}

\textbf{Theorem 2.9} Es sei $A$ ein Online-Algorithmus und $r \geq 1$. Gibt es eine Konstante $b \geq 0$ und eine Potentialfunktion $\Phi$, die die folgenden drei Bedingungen für jede Eingabe $\sigma$ erfüllt, so erreicht Algorithmus $A$ einen kompetitiven Faktor von $r$.
\begin{enumerate}
\item Für jedes $i \geq 1$ gilt $E[a_i] \leq r \cdot \textrm{OPT}_i$.\\
(Die amortisierten Kosten sind höchstens $r$ mal größer als die Kosten von OPT.)
\item Es gilt $E[\Phi_0] \leq b$.\\
(Der Kontostand ist zu Beginn durch eine Konstante nach oben beschränkt.)
\item Für jedes $i \geq 1$ gilt $E[\Phi_i] \geq -b$.\\
(Zu keinem Zeitpunkt wird das Konto stärker als eine Konstante überzogen.)
\end{enumerate}

\textit{Beweisidee:} Da der Startkontostand bzw. das Überziehen des Kontos durch eine Konstante beschränkt sind, kann dies durch das $\tau$ in der Ungleichung des kompetitiven Faktors ausgeglichen werden.


\subsection{Analyse von RANDOM}


\textbf{Theorem 2.10} Der Algorithmus RANDOM ist $k$-kompetitiv.

\textit{Beweisidee:} To be done...



\textbf{Lemma 2.11} Es sei $X$ eine geometrisch verteilte Zufallsvariable mit Parameter $p$ und es sei $n \in \mathbb{N}$. Für die Zufallsvariable $Y = min\{X,n\}$ gilt $$E[Y] = \frac{1-(1-p)^n}{p}$$

\textit{Vermutlich ist dieses Lemma für die Prüfung nicht relevant, da es sich nur um Rechnerei handelt.}



\textbf{Theorem 2.12} Der kompetitive Faktor von RANDOM beträgt mindestens $k$.

\textit{Beweisidee:} Wir betrachten die Sequenz $$\sigma = \left((a_1,...,a_k),(b_1,a_2,...,a_k)^l,(b_2,a_2,...,a_k)^l,...,(b_m,a_2,...,a_k)^l\right)$$.

Bei der Anzahl der Seitenfehler in einer Teilsequenz $(b_i,a_2,...,a_k)^l$ handelt es sich hier um eine bei $l$ abgeschnittene geometrische Zufallsvariable mit Parameter $1/k$. Somit können wir Lemma 2.11 anwenden...


\subsection{Analyse von MARK}

\textbf{Theorem 2.13} Der Algorithmus MARK ist $2H_k$-kompetitiv.

\textit{Beweisidee.} In einer Phase passieren mindestens so viele Seitenfehler, wie es neue Seiten in dieser Phase gibt. Alte Seiten können auch Seitenfehler verursachen, müssen dies aber nicht. Die Wahrscheinlichkeit, dass eine alte Seite einen Seitenfehler verursacht nimmt zu, wenn die Seite später in der Phase angefragt wird, da der Aufruf von neuen Seiten zuvor diese alte Seite aus dem Cache verdrängt haben kann.

\subsection{Untere Schranke für randomisierte Online-Algorithmen}

\textbf{Theorem 2.14} Es existiert kein randomisierter Online-Algorithmus für das Paging-Problem mit einem kleineren kompetitiven Faktor als $H_k$.

\textit{Beweis.} Fehlt noch!
